# /docker-compose.yml (Definitive, All Custom Images Version)

services:
  nginx:
    image: nginx:latest
    container_name: corpus_nginx
    ports:
      - "80:80"
    depends_on:
      - web

  web:
    build: ./server
    container_name: corpus_web_app
    env_file: .env
    volumes:
      - ./server:/app
      - corpus_uploads:/app/uploads
    depends_on:
      - db
      - redis
    command: >
      sh -c "flask init-db && 
             gunicorn --bind 0.0.0.0:5000 --workers 2 --timeout 120 'app:create_app()'"

  worker:
    build: ./server
    container_name: corpus_worker
    env_file: .env
    volumes:
      - ./server:/app
      - corpus_uploads:/app/uploads
    depends_on:
      - redis
      - db
      - tika
      - chroma
      - ollama
    command: >
      # This command waits 25 seconds for all services to initialize before starting.
      # This is more reliable than healthchecks in this environment.
      sh -c "echo 'Worker waiting for services...' &&
             sleep 25 &&
             echo 'Worker starting...' &&
             celery -A celery_worker.celery worker --loglevel=info"

  redis:
    image: redis:7-alpine
    container_name: corpus_redis

  tika:
    # BUILD our custom, stable Tika image
    build:
      context: .
      dockerfile: tika.Dockerfile
    container_name: corpus_tika
    ports:
      - "9998:9998"

  db:
    image: postgres:15
    container_name: corpus_db
    env_file: .env
    volumes:
      - corpus_data:/var/lib/postgresql/data

  chroma:
    # Use the official image, but remove the failing healthcheck
    image: chromadb/chroma
    container_name: corpus_chroma
    ports:
      - "8000:8000"
    volumes:
      - chroma_data:/chroma/.chroma/index
    environment:
      - ANONYMIZED_TELEMETRY=False
      - IS_PERSISTENT=TRUE

  ollama:
    # BUILD our custom Ollama image with the model pre-baked
    build:
      context: .
      dockerfile: ollama.Dockerfile
    container_name: corpus_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  corpus_data:
  chroma_data:
  ollama_data:
  corpus_uploads: