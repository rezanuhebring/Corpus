# /docker-compose.yml (Definitive, Resilient Version)
services:
  nginx:
    image: nginx:latest
    container_name: corpus_nginx
    ports: ["80:80"]
    volumes: ["./nginx.conf:/etc/nginx/conf.d/default.conf:ro"]
    depends_on: [web]

  web:
    build: ./server
    container_name: corpus_web_app
    env_file: .env
    volumes: ["./server:/app", "corpus_uploads:/app/uploads"]
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
    command: >
      sh -c "flask init-db && 
             gunicorn --bind 0.0.0.0:5000 --workers 2 --timeout 120 'app:create_app()'"

  worker:
    build: ./server
    container_name: corpus_worker
    env_file: .env
    volumes: ["./server:/app", "corpus_uploads:/app/uploads"]
    depends_on:
      redis: { condition: service_healthy }
      db: { condition: service_healthy }
      tika: { condition: service_healthy }
      chroma: { condition: service_healthy }
      ollama: { condition: service_healthy }
    command: celery -A app.celery worker --loglevel=info # <<< FIX: Points to the celery instance in app.py

  redis:
    image: redis:7-alpine
    container_name: corpus_redis
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  tika:
    build: 
      context: .
      dockerfile: tika.Dockerfile # <<< OPTIMIZATION: Use custom, smaller Tika image
    container_name: corpus_tika
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9998/tika"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 60s

  db:
    image: postgres:15
    container_name: corpus_db
    env_file: .env
    volumes: ["corpus_data:/var/lib/postgresql/data"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5

  chroma:
    image: chromadb/chroma:0.4.24
    container_name: corpus_chroma
    volumes: ["chroma_data:/chroma/.chroma/index"]
    environment: ["ANONYMIZED_TELEMETRY=False", "IS_PERSISTENT=TRUE"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 10s
      timeout: 5s
      retries: 5

  ollama:
    build:
      context: .
      dockerfile: ollama.Dockerfile
    container_name: corpus_ollama
    volumes: ["ollama_data:/root/.ollama"]
    tty: true
    # The 'deploy' section for GPU has been removed.
    # This environment variable is added to ensure compatibility with CPUs that lack AVX.
    environment:
      - OLLAMA_LLM_LIBRARY=/usr/local/lib/ollama/llm/cpu_avx_off
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

volumes:
  corpus_data: {}
  chroma_data: {}
  ollama_data: {}
  corpus_uploads: {}